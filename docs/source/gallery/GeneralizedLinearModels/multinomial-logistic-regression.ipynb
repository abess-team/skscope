{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2a702d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63a7bf3",
   "metadata": {},
   "source": [
    "## Multinomial logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44388535",
   "metadata": {},
   "source": [
    "We would like to use an example to show how the sparse-constrained optimization for multinomial logistic regression works in our program."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d013f51",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "Multinomial logistic regression is a type of regression analysis used to predict the probabilities of multiple categorical outcomes. It is an extension of binary logistic regression, which is used to predict the probability of a binary outcome.\n",
    "\n",
    "### Mathematical Derivation\n",
    "\n",
    "In multinomial logistic regression, we have multiple categories, denoted by $k=1,2,...,K$. We want to predict the probability of each category given a set of predictor variables $X$. We assume that the probability of each category is a function of the predictor variables, and that the probabilities for each category sum to 1.\n",
    "\n",
    "We can model the probability of each category using the softmax function:\n",
    "\n",
    "$$P(Y=k|X=x) = \\frac{e^{\\beta _{0k} + \\beta _k^TX}}{\\sum_{j=1}^K e^{\\beta _{0j} + \\beta _j^TX}}$$\n",
    "\n",
    "where $Y$ is the categorical outcome, $X$ is the vector of predictor variables, $\\beta _{0k}$ and $\\beta _k$ are the intercept and coefficient vectors for category $k$, and $e$ is the base of the natural logarithm.\n",
    "\n",
    "The softmax function ensures that the probabilities for each category sum to 1. The numerator of the function represents the probability of category $k$, and the denominator represents the sum of the probabilities for all categories.\n",
    "\n",
    "We can estimate the coefficients using maximum likelihood estimation. The likelihood function for multinomial logistic regression is:\n",
    "\n",
    "$$L(\\beta) = \\prod _{i=1}^n \\prod _{k=1}^K P(Y_i=k|X_i=x_i)^{I(Y_i=k)}$$\n",
    "\n",
    "where $n$ is the number of observations, $I(Y_i=k)$ is an indicator function that equals 1 if $Y_i=k$ and 0 otherwise, and $P(Y_i=k|X_i=x_i)$ is the predicted probability of category $k$ for observation $i$.\n",
    "\n",
    "The negative log-likelihood function is:\n",
    "\n",
    "<a id='loss'></a>\n",
    "$$-l(\\beta) = -\\sum _{i=1}^n \\sum _{k=1}^K I(Y_i=k) \\log P(Y_i=k|X_i=x_i) \\tag{1}$$\n",
    "\n",
    "This is the function that we want to minimize in order to estimate the coefficients. We can use scope algorithm to find the values of $\\beta$ with sparsity constraints that minimize the negative log-likelihood function.\n",
    "\n",
    "Here is Python code for solving sparse gamma regression problem:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c91f44",
   "metadata": {},
   "source": [
    "### Import necessary packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81c0c377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from skscope import ScopeSolver\n",
    "import numpy as np\n",
    "from abess.datasets import make_multivariate_glm_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5cfa76",
   "metadata": {},
   "source": [
    "### Set a seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bebb83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f49d60",
   "metadata": {},
   "source": [
    "### Generate the data\n",
    "\n",
    "Firstly, we shall conduct Multinomial logistic regression on an artificial dataset for demonstration. The `make_multivariate_glm_data` from `abess.datasets` function allows us to generate simulated data by specifying the `family=\"multinomial\"`. \n",
    "\n",
    "The assumption behind this model is that the response vector follows a multinomial distribution. The artificial dataset contains 500 observations and 20 predictors but only five predictors have influence on the three possible classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad40fc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real variables' index:\n",
      " {0, 3, 7, 10, 19}\n",
      "real variables:\n",
      " [[  5.44916029  -0.94953634   0.        ]\n",
      " [  0.           0.           0.        ]\n",
      " [  0.           0.           0.        ]\n",
      " [ -1.39241163 -12.96678673   0.        ]\n",
      " [  0.           0.           0.        ]\n",
      " [  0.           0.           0.        ]\n",
      " [  0.           0.           0.        ]\n",
      " [  3.24543565   4.02033588   0.        ]\n",
      " [  0.           0.           0.        ]\n",
      " [  0.           0.           0.        ]\n",
      " [ -1.38210809   4.07755579   0.        ]\n",
      " [  0.           0.           0.        ]\n",
      " [  0.           0.           0.        ]\n",
      " [  0.           0.           0.        ]\n",
      " [  0.           0.           0.        ]\n",
      " [  0.           0.           0.        ]\n",
      " [  0.           0.           0.        ]\n",
      " [  0.           0.           0.        ]\n",
      " [  0.           0.           0.        ]\n",
      " [  5.79719104   3.61096451   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "n = 500  # sample size\n",
    "p = 20  # all predictors\n",
    "k = 5   # real predictors\n",
    "m = 3   # number of classes\n",
    "\n",
    "data = make_multivariate_glm_data(n=n, p=p, k=k, family=\"multinomial\", M=m)\n",
    "\n",
    "X = data.x\n",
    "y = data.y\n",
    "\n",
    "print('real variables\\' index:\\n', set(np.nonzero(data.coef_)[0]))\n",
    "print('real variables:\\n', data.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b20d462",
   "metadata": {},
   "source": [
    "### Define multinomial regression loss\n",
    "\n",
    "Secondly, to carry out sparse-constrained optimization for multinomial logistic regression, we define the loss function `multinomial_regression_loss` accorting to [1](#loss) that matches the data generating function `make_multivariate_glm_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4b7d974",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multinomial_regression_loss(params):\n",
    "    beta = params.reshape((p, m))\n",
    "    # Compute the logits\n",
    "    logits = jnp.dot(X, beta)\n",
    "\n",
    "    # Compute the softmax probabilities\n",
    "    softmax_probs = jnp.exp(logits) / jnp.sum(jnp.exp(logits), axis=1, keepdims=True)\n",
    "\n",
    "    # Compute the NLL loss\n",
    "    loss = -jnp.mean(jnp.sum(y * jnp.log(softmax_probs), axis=1))\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d00a115",
   "metadata": {},
   "source": [
    "### Use skscope to solve the sparse multinomial logistic regression problem\n",
    "\n",
    "After defining the data and the loss function, we can call `ScopeSolver` to solve the sparse-constrained optimization problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8aa62051",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = ScopeSolver(p*(m), k, group=[i for i in range(p) for j in range(m)])\n",
    "params = solver.solve(multinomial_regression_loss, jit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c74cee2",
   "metadata": {},
   "source": [
    "Now the `solver.params` contains the coefficients of multinomial logistic model with no more than 5 variables. That is, those variables with a coefficient 0 is unused in the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec38527e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.39822362 -2.50996204 -1.88825765]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 3.99429591 -9.68531333  5.69101694]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.93656944  2.00800227 -2.94457135]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [-2.31647311  3.43094489 -1.11447062]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 2.54118658  0.82594677 -3.36713346]]\n"
     ]
    }
   ],
   "source": [
    "print(solver.params.reshape((p, m)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5770f5b5",
   "metadata": {},
   "source": [
    "We can further compare the coefficients estimated by `skscope` and the real coefficients in two-fold:\n",
    "\n",
    "* The true support set and the estimated support set\n",
    "\n",
    "* The true nonzero parameters and the estimated nonzero parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c6fcb86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real variables' index:\n",
      " {0, 3, 7, 10, 19}\n",
      "Estimated variables' index:\n",
      " {0, 3, 7, 10, 19}\n"
     ]
    }
   ],
   "source": [
    "print('real variables\\' index:\\n', set(np.nonzero(data.coef_)[0]))\n",
    "print('Estimated variables\\' index:\\n', set(np.nonzero(solver.params.reshape((p, m)))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3321d97b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True parameter:\n",
      " [[  5.44916029  -0.94953634   0.        ]\n",
      " [  0.           0.           0.        ]\n",
      " [  0.           0.           0.        ]\n",
      " [ -1.39241163 -12.96678673   0.        ]\n",
      " [  0.           0.           0.        ]\n",
      " [  0.           0.           0.        ]\n",
      " [  0.           0.           0.        ]\n",
      " [  3.24543565   4.02033588   0.        ]\n",
      " [  0.           0.           0.        ]\n",
      " [  0.           0.           0.        ]\n",
      " [ -1.38210809   4.07755579   0.        ]\n",
      " [  0.           0.           0.        ]\n",
      " [  0.           0.           0.        ]\n",
      " [  0.           0.           0.        ]\n",
      " [  0.           0.           0.        ]\n",
      " [  0.           0.           0.        ]\n",
      " [  0.           0.           0.        ]\n",
      " [  0.           0.           0.        ]\n",
      " [  0.           0.           0.        ]\n",
      " [  5.79719104   3.61096451   0.        ]]\n",
      "Estimated parameter:\n",
      " [[ 4.39822362 -2.50996204 -1.88825765]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 3.99429591 -9.68531333  5.69101694]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.93656944  2.00800227 -2.94457135]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [-2.31647311  3.43094489 -1.11447062]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 2.54118658  0.82594677 -3.36713346]]\n"
     ]
    }
   ],
   "source": [
    "print(\"True parameter:\\n\", data.coef_)\n",
    "print(\"Estimated parameter:\\n\", solver.params.reshape((p, m)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p38",
   "language": "python",
   "name": "p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
